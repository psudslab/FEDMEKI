models:
  octavius:
    model_name: Octavius
    agent_name: DeepSpeedAgent
    stage1_train_dataset: OctaviusDataset
    test_dataset: SelfInstructTestDataset

# ========= Global configuration ========== #
logging_step: 5
# ========= Global configuration ========== #

# generation hyper-parameters
max_len: 512
penalty_alpha: 0.6
top_k: 10
top_p: 0.7
random_prefix_len: 5
sample_num: 2
decoding_method: sampling
generate_len: 512
# some train configuration, more can be found under dsconfig folder
seed: 2024
warmup_rate: 0.1
epochs: 2
max_length: 1024
max_shard_size: 10GB

# peft config
peft_type: moe_lora
lora_r: 32
lora_alpha: 32
lora_dropout: 0.1
lora_target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj']
moe_lora_num_experts: 6
moe_gate_mode: top2_gate

# pcl modality
num_query_rsp_3d: 16
hidden_size_rsp_3d: 768
num_layers_rsp_3d: 1
num_heads_rsp_3d: 8

octavius_modality: ['image', 'pcl']

# dataset
data_path_2d: ../data/Octavius/2D_Instruct/meta_file/octavius_2d_train_293k.json
data_path_3d: ../data/Octavius/3D_Instruct/meta_file/scan2inst_train.json
vision_root_path_2d: ../data/Octavius/2D_Instruct
vision_root_path_3d: ../data/Octavius/3D_Instruct
loop_2d: 1
loop_3d: 2

# deepspeed arguments
deepspeed:
  train_batch_size: 64 # 64
  train_micro_batch_size_per_gpu: 1
  gradient_accumulation_steps: 8
  gradient_clipping: 1.0
  steps_per_print: 1

  zero_optimization:
    allgather_bucket_size: 500000000
    allgather_partitions: true
    contiguous_gradients: true
    stage: 1

  optimizer:
    type: Adam
    params:
      betas:
      - 0.9
      - 0.95
      eps: 1.0e-08
      lr: 0.0005
      weight_decay: 0.001
    
  scheduler:
    type: WarmupDecayLR
    params:
      total_num_steps: 20000
      warmup_max_lr: 0.0005
      warmup_min_lr: 0
      warmup_num_steps: 10

  fp16:
    enabled: true
    min_loss_scale: 1
    opt_level: O2
  
  bf16:
    enable: false

  activation_checkpointing:
    partition_activations: true
    cpu_checkpointing: true
    contiguous_memory_optimization: false
    number_checkpoints: null
    synchronize_checkpoint_boundary: false
    profile: false
